{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import random\n",
    "import pandas as pd\n",
    "from statistics import mode\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\",\n",
    "            \"creative\", \"height\", \"featured\", \"differ\", \"width\", \"other\",\n",
    "            \"energy\", \"business\", \"message\", \"volumes\", \"revision\", \"path\",\n",
    "            \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\",\n",
    "            \"square_bracket\", \"ampersand\"\n",
    "        ]\n",
    "assert len(features) == 32\n",
    "class_names = [\"Ham\", \"Spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    class Node:\n",
    "        def __init__(self, split_rule, left, right, label, is_leaf):\n",
    "            self.split_rule = split_rule\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.label = label\n",
    "            self.is_leaf = is_leaf # 1 = stop \n",
    "            \n",
    "        def __repr__(self):\n",
    "            \"\"\"\n",
    "            TODO: one way to visualize the decision tree is to write out a __repr__ method\n",
    "            that returns the string representation of a tree. Think about how to visualize\n",
    "            a tree structure. You might have seen this before in CS61A.\n",
    "            \"\"\"\n",
    "            def viz(Node, prefix, symbol):\n",
    "                if not Node:\n",
    "                    return prefix + '[]'\n",
    "                if Node.is_leaf == 1:\n",
    "                    return(prefix + '(Therefore the email was: '+ class_names[Node.label] + ')')\n",
    "                else:\n",
    "                    ret = (prefix + '[Feature: '+ features[Node.split_rule[0]] + \n",
    "                           ', Threshold: '+symbol+ str(Node.split_rule[1]) + ']')\n",
    "                    ret += '\\n' + viz(Node.left, prefix + '\\t','<=') + '\\n' + viz(Node.right, prefix + '\\t','>')\n",
    "                    return ret\n",
    "                \n",
    "            return viz(self, \"\",'<=')\n",
    "    \n",
    "        \n",
    "    def __init__(self, max_depth = 200):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def max_count(self, array):\n",
    "        return stats.mode(array, nan_policy='omit')[0][0]\n",
    "    \n",
    "\n",
    "    def entropy(self,y):\n",
    "        p = y / (np.sum(y)+1e-10)\n",
    "        return -p.dot(np.log2(p+1e-10))\n",
    "    \n",
    "\n",
    "    def entropy_impurity(self,left_y_freq, right_y_freq):\n",
    "        Sl = np.sum(left_y_freq)\n",
    "        Sr = np.sum(right_y_freq)\n",
    "        return (Sl * self.entropy(left_y_freq) + Sr * self.entropy(right_y_freq)) / (Sl+Sr)\n",
    "    \n",
    "\n",
    "    def information_gain(self,left_y_freq, right_y_freq):\n",
    "        total = left_y_freq + right_y_freq\n",
    "        if self.entropy(total) == 0: # see if it is pure\n",
    "            return -1\n",
    "        else:\n",
    "            infor_gain = self.entropy(total) - self.entropy_impurity(left_y_freq, right_y_freq)\n",
    "        return infor_gain\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def gini(y): \n",
    "#         p = y / (np.sum(y)+1e-20)\n",
    "#         gini = 1-np.sum(p**2)\n",
    "#         return gini\n",
    "\n",
    "#     @staticmethod\n",
    "#     def gini_impurity(left_label_freq, right_label_freq): # useless\n",
    "#         Sl = np.sum(left_label_freq)\n",
    "#         Sr = np.sum(right_label_freq)\n",
    "#         return (Sl * gini(left_label_freq) + Sr * gini(right_label_freq)) / (Sl+Sr)\n",
    "\n",
    "#     @staticmethod \n",
    "#     def gini_purification(X, y, thresh):\n",
    "#         \"\"\"\n",
    "#         TODO: implement a method that calculates reduction in impurity gain given a vector of features\n",
    "#         and a split threshold\n",
    "#         \"\"\"\n",
    "#         return 0\n",
    "    \n",
    "    def split(self, S, depth, random_f = -1, verbose = False): # recursively\n",
    "        \"\"\"\n",
    "        TODO: implement a method that return a split of the dataset given an index of the feature and\n",
    "        a threshold for it\n",
    "        \"\"\"\n",
    "#         print((depth-1) * '    '+'Depth: '+ str(depth))\n",
    "        if depth >= self.max_depth: \n",
    "#             print('label: '+ str(self.max_count(self.labels[S])))\n",
    "            node = self.Node(left=None, right=None, split_rule=None, is_leaf=1, label=self.max_count(self.labels[S]))\n",
    "            if verbose == True:\n",
    "                print(repr(node))\n",
    "            return node\n",
    "        else:\n",
    "            max_feature, max_thresh = self.segmenter(self.data[S, :], self.labels[S],random_f = random_f)\n",
    "            \n",
    "#             print((depth-1) * '    '+'depth:' + str(depth)  + ', feature index: ' + str(max_feature) +', threshold: ' + str(max_thresh))\n",
    "            Sl = [i for i in S if self.data[i, max_feature] <= max_thresh]\n",
    "            Sr = [i for i in S if self.data[i, max_feature] > max_thresh]\n",
    "#             print((depth-1) * '    '+\"left group: \" + str(len(Sl)) + ', right group: ' + str(len(Sr)))\n",
    "            if len(Sl) <= 5 or len(Sr) <= 5: \n",
    "#                 print('label: '+ str(self.max_count(self.labels[S])))\n",
    "                node = self.Node(left=None, right=None, split_rule=None, is_leaf=1, label=self.max_count(self.labels[S]))\n",
    "                if verbose == True:\n",
    "                    print(repr(node))\n",
    "                return node\n",
    "            else:\n",
    "                node = self.Node(left=self.split(Sl, depth+1, random_f), right=self.split(Sr,depth+1,random_f), split_rule = (max_feature, max_thresh), is_leaf=0, label=None)\n",
    "                if verbose == True:\n",
    "                    print(repr(node))\n",
    "                return node\n",
    "    \n",
    "    \n",
    "    def iter_thresh(self, X, y):\n",
    "        \"\"\"\n",
    "        A method that return the max threshold and max information gain for one feature\n",
    "        \"\"\"\n",
    "        row_f = sorted(set(X)) \n",
    "        col_l = set(y)\n",
    "        freq_matrix = np.zeros([len(row_f), len(col_l)])\n",
    "        for i, j in enumerate(row_f):\n",
    "            for k, l in enumerate(col_l):\n",
    "                freq_matrix[i, k] = len(y[np.where(y[np.where(X==j)]==l)])\n",
    "        all_thresh = np.array(row_f[1:] + row_f[-1:]) / 2.\n",
    "        left_freq = np.zeros([len(col_l)])\n",
    "        right_freq = np.sum(freq_matrix, axis=0)\n",
    "        left_freq_sum = 0\n",
    "        max_thresh = all_thresh[0]\n",
    "        \n",
    "        max_gain = self.information_gain(left_freq, right_freq)\n",
    "        for i, thresh in enumerate(all_thresh):\n",
    "            left_freq += freq_matrix[i, :]\n",
    "            right_freq -= freq_matrix[i, :]\n",
    "            gain = self.information_gain(left_freq, right_freq)\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                max_thresh = thresh\n",
    "        return max_thresh, max_gain\n",
    "    \n",
    "    \n",
    "    def segmenter(self, X, y, random_f = -1):\n",
    "        \"\"\"\n",
    "        TODO: compute entropy gain for all single-dimension splits,\n",
    "        return the feature and the threshold for the split that\n",
    "        has maximum gain\n",
    "        \"\"\"        \n",
    "        x = X.shape[1]\n",
    "        if random_f == -1:\n",
    "            all_features = np.arange(x)\n",
    "        else:\n",
    "            all_features = np.random.choice(range(x), random_f)\n",
    "            \n",
    "        all_features = np.arange(x)\n",
    "        max_gain = 1e-10\n",
    "        max_thresh = 0\n",
    "        max_feature = 0\n",
    "        for i in all_features:\n",
    "            thresh, gain = self.iter_thresh(X[:, i], y)\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                max_thresh = thresh\n",
    "                max_feature = i\n",
    "        return max_feature, max_thresh\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, random_f = -1, verbose = True):\n",
    "        \"\"\"\n",
    "        TODO: fit the model to a training set. Think about what would be \n",
    "        your stopping criteria\n",
    "        \"\"\"\n",
    "        self.data = X\n",
    "        self.labels = y\n",
    "        S = np.array(range(len(y)))\n",
    "        self.root = self.split(S, 1 , random_f = random_f, verbose = verbose)\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def predict(self, X, T = 0):\n",
    "        \"\"\"\n",
    "        TODO: predict the labels for input data \n",
    "        \"\"\"\n",
    "        if T == 1:  # T = 1, for random forest\n",
    "            X = np.reshape(X, [1, len(X)])\n",
    "            row_num = 1\n",
    "        else:\n",
    "            row_num = X.shape[0]\n",
    "        labels = np.zeros(row_num)    \n",
    "        depth = 0    \n",
    "        for i in range(row_num): \n",
    "            current_node = self.root\n",
    "            while current_node.is_leaf == 0: \n",
    "                feature = current_node.split_rule[0]\n",
    "                thresh = current_node.split_rule[1]\n",
    "                if X[i,:][feature] <= thresh:\n",
    "                    current_node = current_node.left\n",
    "                else:\n",
    "                    current_node = current_node.right\n",
    "            depth += 1\n",
    "            labels[i] = current_node.label\n",
    "        return labels\n",
    "    \n",
    "    def accuracy(self, X, y_val, T = 0):\n",
    "        y_pred = self.predict(X, T = T)\n",
    "        len_y = float(len(y_pred))\n",
    "        return np.sum(y_pred == y_val) / len_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \n",
    "    def __init__(self, n_trees=20, n_sample=1000, random_f=-1, max_depth=200):\n",
    "        \"\"\"\n",
    "        TODO: initialization of a random forest\n",
    "        \"\"\"\n",
    "        self.n_trees = n_trees\n",
    "        self.n_sample = n_sample\n",
    "        self.random_f = random_f\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = np.array([DecisionTree(max_depth)] * n_trees)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: fit the model to a training set.\n",
    "        \"\"\"\n",
    "        if self.random_f == -1:\n",
    "            self.random_f = int(np.sqrt(X.shape[1])) \n",
    "        results = np.zeros(self.n_trees, dtype=object)\n",
    "        for i, dt in enumerate(self.trees):\n",
    "            print('#%d. tree' % i)\n",
    "            idx = np.random.choice(range(len(X)), self.n_sample)\n",
    "            sub_X = X[idx, :]\n",
    "            sub_y = y[idx]\n",
    "            results[i] = dt.fit(sub_X, sub_y, random_f=self.random_f, verbose = False)\n",
    "        self.trees = results\n",
    "\n",
    "    def predict(self, X, T = 1):\n",
    "        \"\"\"\n",
    "        TODO: predict the labels for input data \n",
    "        \"\"\"\n",
    "        row_num = X.shape[0]\n",
    "        labels = []    \n",
    "        for i in range(row_num):\n",
    "            pred = np.zeros(self.n_trees)\n",
    "            for j, dt in enumerate(self.trees):\n",
    "                pred[j] = dt.predict(X[i, :], T = T)\n",
    "            labels.append(dt.max_count(pred))\n",
    "        return labels\n",
    "    \n",
    "    def accuracy(self, X, y_val, T = 1):\n",
    "        y_pred = self.predict(X,T = T)\n",
    "        N = float(len(y_pred))\n",
    "        return np.sum(y_pred == y_val) / N\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X):\n",
    "    Xn = np.zeros(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i, :]\n",
    "        Xn[i, :] = (x- np.min(x)/(np.max(x)-np.min(x)))\n",
    "    return Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spam data\n",
    "spam = scipy.io.loadmat('datasets/spam-dataset/spam_data.mat')\n",
    "train_X = spam['training_data']\n",
    "train_y = spam['training_labels'].ravel()\n",
    "test_X = spam['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "idx = np.random.choice(range(len(train_y)), int(len(train_y)), replace=False)\n",
    "train_size = int(len(train_X)*0.8)\n",
    "X_train = train_X[idx,:][:train_size,:]\n",
    "y_train = train_y[idx][:train_size]\n",
    "X_val = train_X[idx,:][train_size:,:]\n",
    "y_val = train_y[idx][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature: exclamation, Threshold: <=0.5]\n",
      "\t[Feature: meter, Threshold: <=0.5]\n",
      "\t\t[Feature: parenthesis, Threshold: <=0.5]\n",
      "\t\t\t[Feature: ampersand, Threshold: <=0.5]\n",
      "\t\t\t\t[Feature: volumes, Threshold: <=0.5]\n",
      "\t\t\t\t\t[Feature: semicolon, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t[Feature: pain, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t[Feature: square_bracket, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t[Feature: prescription, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t[Feature: energy, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t[Feature: drug, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t[Feature: energy, Threshold: >1.0]\n",
      "\t\t\t\t\t\t\t\t\t\t\t[Feature: dollar, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t[Feature: dollar, Threshold: >0.5]\n",
      "\t\t\t\t\t\t\t[Feature: square_bracket, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t[Feature: dollar, Threshold: >0.5]\n",
      "\t\t\t\t[Feature: featured, Threshold: <=0.5]\n",
      "\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t[Feature: private, Threshold: >0.5]\n",
      "\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t(Therefore the email was: Ham)\n",
      "\t[Feature: meter, Threshold: >0.5]\n",
      "\t\t[Feature: ampersand, Threshold: <=0.5]\n",
      "\t\t\t[Feature: money, Threshold: <=0.5]\n",
      "\t\t\t\t[Feature: dollar, Threshold: <=1.0]\n",
      "\t\t\t\t\t[Feature: prescription, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t[Feature: parenthesis, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t[Feature: pain, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t[Feature: message, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t[Feature: other, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t[Feature: semicolon, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t[Feature: sharp, Threshold: <=1.0]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t[Feature: square_bracket, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t[Feature: dollar, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t[Feature: exclamation, Threshold: >1.0]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t[Feature: semicolon, Threshold: >1.0]\n",
      "\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t[Feature: spam, Threshold: >0.5]\n",
      "\t\t\t\t\t\t\t\t[Feature: message, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t[Feature: drug, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t[Feature: featured, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t[Feature: volumes, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t[Feature: semicolon, Threshold: <=0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t\t\t\t[Feature: semicolon, Threshold: >0.5]\n",
      "\t\t\t\t\t\t\t\t\t\t[Feature: parenthesis, Threshold: <=2.0]\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t[Feature: message, Threshold: >2.5]\n",
      "\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t\t(Therefore the email was: Spam)\n",
      "\t\t\t[Feature: other, Threshold: >0.5]\n",
      "\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t\t\t(Therefore the email was: Ham)\n",
      "\t\t(Therefore the email was: Ham)\n",
      "<__main__.DecisionTree object at 0x000001EF5B84F400>\n",
      "Training accuracy:  0.8286197727822093\n",
      "Validation accuracy:  0.8144927536231884\n"
     ]
    }
   ],
   "source": [
    "# try training\n",
    "dt = DecisionTree(16)\n",
    "dt.fit(X_train, y_train, verbose = True)\n",
    "print(repr(dt)) \n",
    "train_acc = dt.accuracy(X_train, y_train)\n",
    "print('Training accuracy: ', train_acc)\n",
    "val_acc = dt.accuracy(X_val, y_val)\n",
    "print('Validation accuracy: ', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "2 \n",
      "3 \n",
      "4 \n",
      "5 \n",
      "6 \n",
      "7 \n",
      "8 \n",
      "9 \n",
      "10 \n",
      "11 \n",
      "12 \n",
      "13 \n",
      "14 \n",
      "15 \n",
      "16 \n",
      "17 \n",
      "18 \n",
      "19 \n",
      "20 \n",
      "21 \n",
      "22 \n",
      "23 \n",
      "24 \n",
      "25 \n",
      "26 \n",
      "27 \n",
      "28 \n",
      "29 \n",
      "30 \n",
      "31 \n",
      "32 \n",
      "33 \n",
      "34 \n",
      "35 \n",
      "36 \n",
      "37 \n",
      "38 \n",
      "39 \n",
      "40 \n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for i in range(40):\n",
    "    print(str(i+1))\n",
    "    dt = DecisionTree(i+1)\n",
    "    dt.fit(X_train, y_train, verbose = False)\n",
    "    acc = dt.accuracy(X_val, y_val)\n",
    "    accuracy_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy_list\n",
    "mylist = np.linspace(1,40,40)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(mylist,accuracy_list)\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('accuracy')\n",
    "fig.savefig('1-40depth-accuracy-dt.png')\n",
    "\n",
    "# when the depth is equal or larger than 15, the validation accuracy is stable and the largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0. tree\n",
      "#1. tree\n",
      "#2. tree\n",
      "#3. tree\n",
      "#4. tree\n",
      "#5. tree\n",
      "#6. tree\n",
      "#7. tree\n",
      "#8. tree\n",
      "#9. tree\n",
      "#10. tree\n",
      "#11. tree\n",
      "#12. tree\n",
      "#13. tree\n",
      "#14. tree\n",
      "#15. tree\n",
      "#16. tree\n",
      "#17. tree\n",
      "#18. tree\n",
      "#19. tree\n",
      "Training accuracy:  0.8300700991056321\n",
      "Validation accuracy:  0.8241545893719807\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_trees=20, n_sample=len(y_train), random_f=-1, max_depth=20)\n",
    "rf.fit(X_train, y_train) # use all data\n",
    "train_acc = rf.accuracy(X_train,y_train)\n",
    "print('Training accuracy: ', train_acc)\n",
    "val_acc = rf.accuracy(X_val,y_val)\n",
    "print('Validation accuracy: ', val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
